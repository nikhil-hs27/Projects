{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38720299",
   "metadata": {},
   "source": [
    "Name: Nikhil Arora\n",
    "\n",
    "Student ID: 20848206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da05f3",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f215f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f494a",
   "metadata": {},
   "source": [
    "## Importing and Reshaping the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625e06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)) \n",
    "\n",
    "# Normalizing the pixel values to be in the range [0, 1] \n",
    "# by dividing them by 255\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# Converting the labels into one-hot vectors\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb52c99",
   "metadata": {},
   "source": [
    "# Task 1: Build a neural network without convolutional layers to do the classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65b556",
   "metadata": {},
   "source": [
    "### Step 1: Defining a Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03c9216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nikhi\\anaconda3\\envs\\NeuralNetwork\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model_T1 = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model_T1.add(Flatten(input_shape=(28, 28, 1)))\n",
    "\n",
    "#Hidden Layers\n",
    "model_T1.add(Dense(128, activation='relu'))\n",
    "model_T1.add(Dense(64, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "model_T1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5cfd3",
   "metadata": {},
   "source": [
    "### Step 2: Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d748160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Optimizer, loss function and evaluation metrics\n",
    "model_T1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf31dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Structure\n",
    "model_T1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c4796",
   "metadata": {},
   "source": [
    "### Step 3: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd82c5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_9356\\3595446061.py:2: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nikhi\\anaconda3\\envs\\NeuralNetwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.4904 - accuracy: 0.8259 - val_loss: 0.4505 - val_accuracy: 0.8413\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3691 - accuracy: 0.8654 - val_loss: 0.3945 - val_accuracy: 0.8534\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3340 - accuracy: 0.8770 - val_loss: 0.3775 - val_accuracy: 0.8679\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3108 - accuracy: 0.8848 - val_loss: 0.3574 - val_accuracy: 0.8713\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2935 - accuracy: 0.8900 - val_loss: 0.3512 - val_accuracy: 0.8673\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2771 - accuracy: 0.8977 - val_loss: 0.3364 - val_accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2668 - accuracy: 0.8999 - val_loss: 0.3398 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2557 - accuracy: 0.9046 - val_loss: 0.3461 - val_accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2450 - accuracy: 0.9086 - val_loss: 0.3459 - val_accuracy: 0.8791\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2366 - accuracy: 0.9113 - val_loss: 0.3466 - val_accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17b3c105188>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting a random state so that comparing the evaluation metrics is possible\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model_T1.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a6500",
   "metadata": {},
   "source": [
    "### Step 4: Evaluating the model with Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463956e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step\n",
      "accuracy: 88.54%\n"
     ]
    }
   ],
   "source": [
    "scores = model_T1.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model_T1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820b740",
   "metadata": {},
   "source": [
    "### Step 5: Changing the Model Structure to get better evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be010ac",
   "metadata": {},
   "source": [
    "Changing the number of neurons: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ea5aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/step\n",
      "accuracy: 88.70%\n"
     ]
    }
   ],
   "source": [
    "model_T1 = Sequential()\n",
    "model_T1.add(Flatten(input_shape=(28, 28, 1)))\n",
    "model_T1.add(Dense(256, activation='relu'))\n",
    "model_T1.add(Dense(128, activation='relu'))\n",
    "model_T1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Defining Optimizer, loss function and evaluation metrics\n",
    "model_T1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Setting a random state so that comparing the evaluation metrics is possible\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "model_T1.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), verbose = 0)\n",
    "\n",
    "scores = model_T1.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model_T1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25b348",
   "metadata": {},
   "source": [
    "# Task 2: Build a neural network with the use of convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa2b48",
   "metadata": {},
   "source": [
    "### Step 1: Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b57bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nikhi\\anaconda3\\envs\\NeuralNetwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_T2 = Sequential()\n",
    "#Convolutional Layer 1\n",
    "model_T2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), \n",
    "                   padding='same'))\n",
    "#Pooling Layer 1\n",
    "model_T2.add(MaxPooling2D((2, 2)))\n",
    "#Convolutional Layer 2\n",
    "model_T2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "#Pooling Layer 1\n",
    "model_T2.add(MaxPooling2D((2, 2)))\n",
    "#Flatten Layer\n",
    "model_T2.add(Flatten())\n",
    "#Fully-Connected Layer 1\n",
    "model_T2.add(Dense(128, activation='relu'))\n",
    "#Fully-Connected Layer 2 (Output Layer)\n",
    "model_T2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e23707",
   "metadata": {},
   "source": [
    "### Step 2: Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc971d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Optimizer, loss function and evaluation metrics\n",
    "from keras.optimizers import Adam\n",
    "custom_adam = Adam(lr=0.002)\n",
    "\n",
    "model_T2.compile(loss='categorical_crossentropy', optimizer=custom_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51824d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Structure\n",
    "model_T2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f9b61",
   "metadata": {},
   "source": [
    "### Step 3: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29561fd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 58s 959us/step - loss: 0.3801 - accuracy: 0.8636 - val_loss: 0.3107 - val_accuracy: 0.8880\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 58s 969us/step - loss: 0.2497 - accuracy: 0.9080 - val_loss: 0.2640 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 58s 972us/step - loss: 0.2082 - accuracy: 0.9222 - val_loss: 0.2709 - val_accuracy: 0.9051\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 59s 991us/step - loss: 0.1769 - accuracy: 0.9334 - val_loss: 0.2417 - val_accuracy: 0.9097\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 58s 966us/step - loss: 0.1491 - accuracy: 0.9435 - val_loss: 0.2567 - val_accuracy: 0.9156\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 59s 979us/step - loss: 0.1269 - accuracy: 0.9513 - val_loss: 0.2710 - val_accuracy: 0.9087\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 58s 967us/step - loss: 0.1072 - accuracy: 0.9589 - val_loss: 0.2906 - val_accuracy: 0.9142\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 59s 985us/step - loss: 0.0922 - accuracy: 0.9656 - val_loss: 0.3263 - val_accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 59s 983us/step - loss: 0.0764 - accuracy: 0.9709 - val_loss: 0.3546 - val_accuracy: 0.9145\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 59s 983us/step - loss: 0.0708 - accuracy: 0.9730 - val_loss: 0.4068 - val_accuracy: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17b3c5a31c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting a random state so that comparing the evaluation metrics is possible\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model_T2.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ff609",
   "metadata": {},
   "source": [
    "### Step 4: Evaluating the model with Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24275ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 232us/step\n",
      "accuracy: 91.14%\n"
     ]
    }
   ],
   "source": [
    "scores = model_T2.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model_T1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ebfbf",
   "metadata": {},
   "source": [
    "### Step 5: Changing the Model Structure to get better evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94364f1f",
   "metadata": {},
   "source": [
    "Changing the model structure by increasing the number of filters in the convolutional layer to 64 and 128 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be6f12e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.3671 - accuracy: 0.8677 - val_loss: 0.2994 - val_accuracy: 0.8927\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.2409 - accuracy: 0.9103 - val_loss: 0.2551 - val_accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.1976 - accuracy: 0.9259 - val_loss: 0.2677 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.1646 - accuracy: 0.9387 - val_loss: 0.2484 - val_accuracy: 0.9119\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.1377 - accuracy: 0.9483 - val_loss: 0.2487 - val_accuracy: 0.9123\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1148 - accuracy: 0.9554 - val_loss: 0.2977 - val_accuracy: 0.9116\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0934 - accuracy: 0.9647 - val_loss: 0.3319 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.3438 - val_accuracy: 0.9174\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0684 - accuracy: 0.9753 - val_loss: 0.3628 - val_accuracy: 0.9175\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.4392 - val_accuracy: 0.9158\n",
      "10000/10000 [==============================] - 5s 455us/step\n",
      "accuracy: 91.58%\n"
     ]
    }
   ],
   "source": [
    "model_T2 = Sequential()\n",
    "model_T2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1),\n",
    "                   padding='same'))\n",
    "model_T2.add(MaxPooling2D((2, 2)))\n",
    "model_T2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_T2.add(MaxPooling2D((2, 2)))\n",
    "model_T2.add(Flatten())\n",
    "model_T2.add(Dense(128, activation='relu'))\n",
    "model_T2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "custom_adam = Adam(lr=0.002)\n",
    "\n",
    "model_T2.compile(loss='categorical_crossentropy', optimizer=custom_adam, metrics=['accuracy'])\n",
    "\n",
    "# Setting a random state so that comparing the evaluation metrics is possible\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "model_T2.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "scores = model_T2.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model_T1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c190b8",
   "metadata": {},
   "source": [
    "## Task 3: Change the type of optimizer or learning rate that you applied in the previous tasks, and see how these changes can influence model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edbc9ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 464us/step\n",
      "learning rate:  0.002\n",
      "accuracy: 92.65%\n",
      "10000/10000 [==============================] - 6s 600us/step\n",
      "learning rate:  0.004\n",
      "accuracy: 92.74%\n",
      "10000/10000 [==============================] - 4s 426us/step\n",
      "learning rate:  0.006\n",
      "accuracy: 92.73%\n",
      "10000/10000 [==============================] - 8s 834us/step\n",
      "learning rate:  0.008\n",
      "accuracy: 92.80%\n"
     ]
    }
   ],
   "source": [
    "#Testing custom sgd with different learning rates\n",
    "lrate = (0.002, 0.004, 0.006, 0.008)\n",
    "for lr in lrate:\n",
    "    epochs = 10\n",
    "    decay = lr/epochs\n",
    "    sgd = SGD(lr=lr, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "    # Compile model\n",
    "    model_T2.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    model_T2.fit(x_train, y_train, epochs=epochs, batch_size=32, validation_data=(x_test, y_test), verbose = 0)\n",
    "    scores = model_T2.evaluate(x_test, y_test, verbose=1)\n",
    "    print(\"learning rate: \", lr)\n",
    "    print(\"%s: %.2f%%\" % (model_T2.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
